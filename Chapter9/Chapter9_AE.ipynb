{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter9_AE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8de1Nagz2tpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENzevbTo2_Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_img(imgs,names):\n",
        "  img_new = Image.new('L',(280,280))\n",
        "  index = 0\n",
        "  for i in range(0,280,80):\n",
        "    for j in range(0,280,80):\n",
        "      img = imgs[index]\n",
        "      img = Image.fromarray(img,mode='L')\n",
        "      img_new.paste(img,(i,j))\n",
        "      index+=1\n",
        "  img_new.save(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6eKQbKl3CcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_scale(x):\n",
        "  x = tf.cast(x,dtype=tf.float32)/255.\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2suf_Eon3EM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dim reduct nums\n",
        "dim_reduce = 10\n",
        "batch_num = 128\n",
        "lr = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHKJenHQ3FlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "45c11bad-5d37-430b-bb92-de3b36299cad"
      },
      "source": [
        "(x,y),(x_test,y_test) = datasets.fashion_mnist.load_data()\n",
        "data = tf.data.Dataset.from_tensor_slices(x)\n",
        "data = data.map(feature_scale).shuffle(10000).batch(batch_num)\n",
        "\n",
        "data_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "data_test = data_test.map(feature_scale).batch(batch_num)\n",
        "data_iter = iter(data)\n",
        "samples = next(data_iter)\n",
        "print(samples[0].shape,samples[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(28, 28) (28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMlQVWYp3IZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AE(keras.Model):\n",
        "  def __init__(self):\n",
        "    super(AE,self).__init__()\n",
        "    #encoder\n",
        "    self.model_encoder = Sequential([layers.Dense(256,activation=tf.nn.relu),\n",
        "                             layers.Dense(128,activation=tf.nn.relu),\n",
        "                             layers.Dense(dim_reduce,activation=tf.nn.relu),\n",
        "                                     \n",
        "                            ])\n",
        "    \n",
        "    #decoder\n",
        "    self.model_decoder = Sequential([layers.Dense(128,activation=tf.nn.relu),\n",
        "                             layers.Dense(256,activation=tf.nn.relu),\n",
        "                             layers.Dense(784,activation=tf.nn.relu),\n",
        "                                     \n",
        "                            ])\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    x = self.model_encoder(inputs)\n",
        "    x = self.model_decoder(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Ukj31K3KRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b401c0ed-01bb-4570-fb4e-d94165c7cb49"
      },
      "source": [
        "model = AE()\n",
        "model.build(input_shape=(None,784))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      multiple                  235146    \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    multiple                  235920    \n",
            "=================================================================\n",
            "Total params: 471,066\n",
            "Trainable params: 471,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT63wKTh3MOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf img_result\n",
        "!mkdir img_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdRk75e43N6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "2e93f562-1dfc-424d-d600-85ca5e79a22e"
      },
      "source": [
        "optimizer = optimizers.Adam(lr=lr)\n",
        "for i in range(10):\n",
        "  for step,x in enumerate(data):\n",
        "    x = tf.reshape(x,[-1,784])\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(x)\n",
        "      loss = tf.losses.binary_crossentropy(x,logits,from_logits=True)\n",
        "      loss = tf.reduce_mean(loss)\n",
        "    grads = tape.gradient(loss,model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
        "    \n",
        "    if step %100==0:\n",
        "      print(i,step,'loss:',float(loss))\n",
        "      \n",
        "  x = next(iter(data_test))\n",
        "  val_x = tf.reshape(x,[-1,784])\n",
        "  logits = model(val_x)\n",
        "  x_hat = tf.sigmoid(logits)\n",
        "  x_hat = tf.reshape(x_hat,[-1,28,28])\n",
        "  x_hat = x_hat.numpy()*255\n",
        "  x_hat = x_hat.astype(np.uint8)\n",
        "  save_img(x_hat,'img_result/AE_img_%d.png'%i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 loss: 0.6942018866539001\n",
            "0 100 loss: 0.6850414276123047\n",
            "0 200 loss: 0.6786310076713562\n",
            "0 300 loss: 0.6799616813659668\n",
            "0 400 loss: 0.6795993447303772\n",
            "1 0 loss: 0.679826021194458\n",
            "1 100 loss: 0.6794265508651733\n",
            "1 200 loss: 0.6824880838394165\n",
            "1 300 loss: 0.6780180335044861\n",
            "1 400 loss: 0.6764596104621887\n",
            "2 0 loss: 0.6795350313186646\n",
            "2 100 loss: 0.6776262521743774\n",
            "2 200 loss: 0.6781857013702393\n",
            "2 300 loss: 0.6745344400405884\n",
            "2 400 loss: 0.6731181144714355\n",
            "3 0 loss: 0.672815203666687\n",
            "3 100 loss: 0.6690542697906494\n",
            "3 200 loss: 0.6690125465393066\n",
            "3 300 loss: 0.6686781644821167\n",
            "3 400 loss: 0.6675901412963867\n",
            "4 0 loss: 0.6702392101287842\n",
            "4 100 loss: 0.6623368859291077\n",
            "4 200 loss: 0.6615491509437561\n",
            "4 300 loss: 0.6631669998168945\n",
            "4 400 loss: 0.663107693195343\n",
            "5 0 loss: 0.6644995212554932\n",
            "5 100 loss: 0.6664038896560669\n",
            "5 200 loss: 0.6646358966827393\n",
            "5 300 loss: 0.6668475866317749\n",
            "5 400 loss: 0.6610640287399292\n",
            "6 0 loss: 0.6575562953948975\n",
            "6 100 loss: 0.6653007864952087\n",
            "6 200 loss: 0.6569972038269043\n",
            "6 300 loss: 0.659725546836853\n",
            "6 400 loss: 0.6619887351989746\n",
            "7 0 loss: 0.6594577431678772\n",
            "7 100 loss: 0.6629432439804077\n",
            "7 200 loss: 0.6612070798873901\n",
            "7 300 loss: 0.6642594337463379\n",
            "7 400 loss: 0.6625086069107056\n",
            "8 0 loss: 0.6583732962608337\n",
            "8 100 loss: 0.66227126121521\n",
            "8 200 loss: 0.6572389006614685\n",
            "8 300 loss: 0.6514788866043091\n",
            "8 400 loss: 0.6626017689704895\n",
            "9 0 loss: 0.6576517820358276\n",
            "9 100 loss: 0.660576343536377\n",
            "9 200 loss: 0.6562004089355469\n",
            "9 300 loss: 0.6612192392349243\n",
            "9 400 loss: 0.6626347899436951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6TFZKKL3POw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('img_result/AE_img_9.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEYD-to74Q_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = next(iter(data_test))\n",
        "val_x = tf.reshape(x,[-1,784])\n",
        "logits = model(val_x)\n",
        "x_pred = tf.sigmoid(logits)\n",
        "x_pred = tf.reshape(x_pred,[-1,28,28])\n",
        "x_pred = tf.concat([x,x_pred],axis=0)\n",
        "x_pred = x_pred.numpy()*255\n",
        "x_pred = x_pred.astype(np.uint8)\n",
        "save_img(x_pred,'img_result/AE_img_total.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxCMgXS94Sgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}